{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asma-Ahmed-Aqil-AL-Zubaidi/Tuwaiq_Academy_week_8/blob/main/Text_Summarization_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00dbdcaa",
      "metadata": {
        "id": "00dbdcaa"
      },
      "source": [
        "# Fine-tuning a Model for Summarization Task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "665ad863",
      "metadata": {
        "id": "665ad863"
      },
      "source": [
        "In this task, you will load, preprocess, and fine-tune a T5 model on a dataset of news articles for a summarization task. Follow the steps below carefully.\n",
        "\n",
        "### Model and Dataset Information\n",
        "\n",
        "For this task, you will be working with the following:\n",
        "\n",
        "- **Model Checkpoint**: Use the pre-trained model checkpoint `UBC-NLP/AraT5-base` if you face any problem you can use `google-t5/t5-small` but the first one is the correct one for both the model and tokenizer.\n",
        "- **Dataset**: You will be using the `CUTD/news_articles_df` dataset. Ensure to load and preprocess the dataset correctly for training and evaluation.\n",
        "\n",
        "**Note:**\n",
        "- Any additional steps or methods you include that improve or enhance the results will be rewarded with bonus points if they are justified.\n",
        "- The steps outlined here are suggestions. You are free to implement alternative methods or approaches to achieve the task, as long as you explain the reasoning and the process at the bottom of the notebook.\n",
        "- You can use either TensorFlow or PyTorch for this task. If you prefer TensorFlow, feel free to use it when working with Hugging Face Transformers.\n",
        "- The number of data samples you choose to work with is flexible. However, if you select a very low number of samples and the training time is too short, this could affect the evaluation of your work."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697bca4c",
      "metadata": {
        "id": "697bca4c"
      },
      "source": [
        "## Step 1: Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3f385d",
      "metadata": {
        "id": "7d3f385d"
      },
      "source": [
        "Load the dataset and split it into training and test sets. Use 20% of the data for testing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXn6LPCLmSNz",
        "outputId": "411a6f84-950b-4e7d-f963-88f7ec088659"
      },
      "id": "PXn6LPCLmSNz",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "id": "XCzvZwUNsDw4",
        "outputId": "120c4af3-0e58-40e1-b13f-b6a0c9a63109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XCzvZwUNsDw4",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.68)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sklearn\n"
      ],
      "metadata": {
        "id": "3QaAJbkcnYDc",
        "outputId": "80274a39-d4ae-4216-82ef-5eda66cae8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3QaAJbkcnYDc",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q29se3u6mUOw",
        "outputId": "c465c855-8349-439c-d993-ef6c616de7b8"
      },
      "id": "Q29se3u6mUOw",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.68)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsteKboomVxy",
        "outputId": "f6e1310c-2201-4efc-afb0-9e9bb7de9dd2"
      },
      "id": "RsteKboomVxy",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainer"
      ],
      "metadata": {
        "id": "E4TDSxQomYky"
      },
      "id": "E4TDSxQomYky",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"CUTD/news_articles_df\")\n",
        "\n",
        "train_data, test_data = train_test_split(dataset['train'], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "test_dataset = Dataset.from_dict(test_data)"
      ],
      "metadata": {
        "id": "Rd5qU0NUKRnO"
      },
      "id": "Rd5qU0NUKRnO",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXD5060dmgEW",
        "outputId": "c22c31c4-a671-4ad3-8874-8519818866dd"
      },
      "id": "jXD5060dmgEW",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Unnamed: 0': [5677, 664, 4366],\n",
              " 'summarizer': ['\\nÙ†Ø¸Ù…Øª Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø­Ø±Ø³ Ø§Ù„ÙˆØ·Ù†ÙŠ Ø¨Ø§Ù„Ù…Ø­Ø±Ø³ ÙˆÙ„Ø§ÙŠØ© ØµÙØ§Ù‚Ø³ ÙŠÙˆÙ… Ø£Ù…Ø³ Ø­Ù…Ù„Ø© Ø£Ù…Ù†ÙŠÙ‘Ø© ÙƒØ¨Ø±Ù‰ Ø¥Ø³ØªØ«Ù†Ø§Ø¦ÙŠÙ‘Ø©ØŒ Ø¨Ø­Ø³Ø¨ Ø¨ÙŠØ§Ù† Ù„ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©. - Ø¥Ø­Ø¨Ø§Ø· Ø¹Ù…Ù„ÙŠÙ‘Ø§Øª ØªÙ‡Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ù…ØªÙ† 05 Ø³ÙŠÙ‘Ø§Ø±Ø§Øª ÙƒØ§Ù†Øª Ù…Ø­Ù…Ù‘Ù„Ø© Ø¨Ø¨Ø¶Ø§Ø¦Ø¹ Ù…Ù‡Ø±Ù‘Ø¨Ø© ØªØªÙ…Ø«Ù„ ÙÙŠ: - 3100 Ù„ØªØ±Ø§ Ù…Ù† Ø§Ù„Ù…Ø­Ø±ÙˆÙ‚Ø§Øª. ÙˆØ£Ø³ÙØ±Øª Ø§Ù„Ø­Ù…Ù„Ø© Ø¹Ù† ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ§Ù„ÙŠØ©: - Ø¥Ù„Ù‚Ø§Ø¡ Ø§Ù„Ù‚Ø¨Ø¶ Ø¹Ù„Ù‰ 17 Ø´Ø®ØµØ§ Ù…ÙØªØ´ Ø¹Ù†Ù‡Ù….',\n",
              "  '\\nØ£ÙƒØ¯ ÙˆØ²ÙŠØ± Ø§Ù„ÙÙ„Ø§Ø­Ø© ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø§Ø¦ÙŠØ© ÙˆØ§Ù„ØµÙŠØ¯ Ø§Ù„Ø¨Ø­Ø±ÙŠ\\xa0Ø³Ù…ÙŠØ± Ø§Ù„Ø·ÙŠØ¨ Ø§Ù†Ù‡ ØªÙ… ØªØ­Ø¯ÙŠØ¯ ØªØ³Ø¹ÙŠØ±Ø© Ø§Ù„Ù„ØªØ± Ø§Ù„ÙˆØ§Ø­Ø¯ Ù…Ù† Ø²ÙŠØª Ø§Ù„Ø²ÙŠØªÙˆÙ† Ø¨8 Ø¯Ù†Ø§Ù†ÙŠØ±\\xa0ÙÙ‚Ø· Ø¨Ø¹Ø¯ Ø§Ù„Ø§ØªÙØ§Ù‚ Ø¨ÙŠÙ† Ø§Ù„ÙˆØ²Ø§Ø±Ø© Ùˆ Ø§Ù„Ø¯ÙŠÙˆØ§Ù† Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø²ÙŠØª.',\n",
              "  'ÙƒÙ…Ø§ ØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù€ 3 Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡Ù… Ø¢Ø®Ø±ÙŠÙ† (ØªØªØ±Ø§ÙˆØ­ Ø£Ø¹Ù…Ø§Ø±Ù‡Ù… Ø¨ÙŠÙ† 22 Ùˆ 40 Ø³Ù†Ø©) ÙˆØ­Ø¬Ø² Ù…Ø¨Ù„Øº Ù…Ø§Ù„ÙŠ Ù‚Ø¯Ø±Ù‡ 8060 Ø¯ÙŠÙ†Ø§Ø± Ùˆ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø© Ø§Ù„Ù†Ø§Ø±ÙŠØ© Ø§Ù„Ù…Ø³ØªØ¹Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© . \\nØ£Ø¹Ù„Ù†Øª ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø«Ù„Ø§Ø«Ø§Ø¡ Ø£Ù†Ù‡ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø£Ø´Ø®Ø§Øµ Ø§Ù„Ù…ØªÙˆØ±Ø·ÙŠÙ† ÙÙŠ Ù‚ØªÙ„ Ø´Ø®Øµ Ø¨Ø¹Ø¯ Ù…Ø­Ø§ÙˆÙ„Ø© Ø³Ù„Ø¨Ù‡ Ø£Ù…ÙˆØ§Ù„Ù‡ ÙÙŠ Ø¬Ø±ÙŠÙ…Ø© ÙˆÙ‚Ø¹Øª ÙÙŠ Ø´Ø§Ø±Ø¹ Ø¢Ù„Ø§Ù† Ø³Ø§ÙØ§Ø±ÙŠ Ø¨ØªÙˆÙ†Ø³ Ø§Ù„Ø¹Ø§ØµÙ…Ø©. ÙˆØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (18Ø³Ù†Ø©) Ø§Ù„Ø°ÙŠ Ø£ÙƒØ¯ Ù…Ø§ Ø¬Ø§Ø¡ Ø¨Ø£Ø·ÙˆØ§Ø± Ø§Ù„Ù‚Ø¶ÙŠØ© ÙˆØ§Ø¹ØªØ±Ù Ø¨Ø·Ø¹Ù†Ù‡ Ù„Ù„Ù…ØªØ¶Ø±Ø± Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø±Ø¬Ù„Ù‡ Ù…Ù…Ø§ Ø£Ø¯Ù‰ Ù„Ø§Ø­Ù‚Ø§ Ù„ÙˆÙØ§ØªÙ‡.'],\n",
              " 'text': ['Ù†Ø¸Ù…Øª Ù…Ù†Ø·Ù‚Ù‡ Ø§Ù„Ø­Ø±Ø³ Ø§Ù„ÙˆØ·Ù†ÙŠ Ø¨Ø§Ù„Ù…Ø­Ø±Ø³ ÙˆÙ„Ø§ÙŠÙ‡ ØµÙØ§Ù‚Ø³ ÙŠÙˆÙ… Ø­Ù…Ù„Ù‡ ÙƒØ¨Ø±Ù‰ Ø¨Ø­Ø³Ø¨ Ø¨ÙŠØ§Ù† Ù„ÙˆØ²Ø§Ø±Ù‡ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠÙ‡ ÙˆØ§Ø³ÙØ±Øª Ø§Ù„Ø­Ù…Ù„Ù‡ ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ§Ù„ÙŠÙ‡ Ø§Ù„Ù‚Ø§Ø¡ Ø§Ù„Ù‚Ø¨Ø¶ Ø´Ø®ØµØ§ Ù…ÙØªØ´ Ø¹Ù†Ù‡Ù… Ø§Ø­Ø¨Ø§Ø· ØªÙ‡Ø±ÙŠØ¨ Ù…ØªÙ† ÙƒØ§Ù†Øª Ø¨Ø¨Ø¶Ø§Ø¦Ø¹ ØªØªÙ…Ø«Ù„ Ù„ØªØ±Ø§ Ø§Ù„Ù…Ø­Ø±ÙˆÙ‚Ø§Øª ÙƒÙ„Øº ØºØ±Ø§Ù… Ø§Ù„ÙØ¶Ù‡ Ø§Ù„Ù‚ÙŠÙ…Ù‡ Ù„Ù„Ù…Ø­Ø¬ÙˆØ² Ø¨',\n",
              "  'Ø§ÙƒØ¯ ÙˆØ²ÙŠØ± Ø§Ù„ÙÙ„Ø§Ø­Ù‡ ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø§Ø¦ÙŠÙ‡ ÙˆØ§Ù„ØµÙŠØ¯ Ø§Ù„Ø¨Ø­Ø±ÙŠ Ø³Ù…ÙŠØ± Ø§Ù„Ø·ÙŠØ¨ Ø§Ù†Ù‡ ØªÙ… ØªØ­Ø¯ÙŠØ¯ ØªØ³Ø¹ÙŠØ±Ù‡ Ø§Ù„Ù„ØªØ± Ø§Ù„ÙˆØ§Ø­Ø¯ Ø²ÙŠØª Ø§Ù„Ø²ÙŠØªÙˆÙ† Ø¯Ù†Ø§Ù†ÙŠØ± ÙÙ‚Ø· Ø§Ù„Ø§ØªÙØ§Ù‚ Ø§Ù„ÙˆØ²Ø§Ø±Ù‡ Ø§Ù„Ø¯ÙŠÙˆØ§Ù† Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø²ÙŠØª Ø¯Ø¹Ø§ ÙˆØ²ÙŠØ± Ø§Ù„ÙÙ„Ø§Ø­Ù‡ Ø¹Ù‚Ø¨ Ø²ÙŠØ§Ø±ØªÙ‡ Ø§Ù„ÙŠÙˆÙ… ÙˆÙ„Ø§ÙŠÙ‡ Ø³ÙˆØ³Ù‡ Ù„Ù„Ø§Ø´Ø±Ø§Ù Ù†Ø¯ÙˆÙ‡ Ø¹Ù„Ù…ÙŠÙ‡ Ø¹Ù†ÙˆØ§Ù† Ù‡Ø´Ø§Ø´Ù‡ ÙÙ„Ø§Ø­Ù‡ Ø§Ù„Ø²ÙŠØªÙˆÙ† ØªØ§Ø«ÙŠØ± Ø§Ù„ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø®ÙŠÙ‡ ØªÙ… Ø¨Ø±Ù…Ø¬ØªÙ‡Ø§ Ø§Ù„ÙŠÙˆÙ… Ø¶Ù…Ù† ÙØ¹Ø§Ù„ÙŠØ§Øª Ø§Ù„Ø§Ø­ØªÙØ§Ù„ Ø¨Ø§Ù„Ù…Ù‡Ø±Ø¬Ø§Ù† Ø§Ù„Ø¯ÙˆÙ„ÙŠ Ù„Ù„Ø²ÙŠØªÙˆÙ†Ù‡ Ø¨Ø§Ù„Ù‚Ù„Ø¹Ù‡ Ø§Ù„ÙƒØ¨Ø±Ù‰ Ø¯ÙˆØ±ØªÙ‡ Ø§Ù„Ù…ÙˆØ§Ø·Ù†ÙŠÙ† Ù„Ù„ØªÙˆØ¬Ù‡ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨ÙŠØ¹ Ø§Ù„ØªØ§Ø¨Ø¹Ù‡ Ù„Ù„Ø¯ÙŠÙˆØ§Ù† Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø²ÙŠØª Ù„Ø´Ø±Ø§Ø¡ Ù…Ø³ØªÙ„Ø²Ù…Ø§ØªÙ‡Ù… Ø§Ù„Ù…Ø§Ø¯Ù‡ ØªÙØ¯ÙŠØ§ Ù„Ø¹Ù…Ù„ÙŠÙ‡ Ø§Ù„ØªÙ„Ø§Ø¹Ø¨ Ø¨Ø§Ù„Ø§Ø³Ø¹Ø§Ø± ÙŠØ´Ù‡Ø¯Ù‡Ø§ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø§Ø­ÙŠØ§Ù†',\n",
              "  'Ø§Ø¹Ù„Ù†Øª ÙˆØ²Ø§Ø±Ù‡ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠÙ‡ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø«Ù„Ø§Ø«Ø§Ø¡ Ø§Ù†Ù‡ ØªÙ… Ø§ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø´Ø®Ø§Øµ Ø§Ù„Ù…ØªÙˆØ±Ø·ÙŠÙ† Ù‚ØªÙ„ Ø´Ø®Øµ Ù…Ø­Ø§ÙˆÙ„Ù‡ Ø³Ù„Ø¨Ù‡ Ø§Ù…ÙˆØ§Ù„Ù‡ Ø¬Ø±ÙŠÙ…Ù‡ ÙˆÙ‚Ø¹Øª Ø´Ø§Ø±Ø¹ Ø§Ù„Ø§Ù† Ø³Ø§ÙØ§Ø±ÙŠ Ø¨ØªÙˆÙ†Ø³ Ø§Ù„Ø¹Ø§ØµÙ…Ù‡ ÙˆØ§ÙˆØ¶Ø­Øª Ø§Ù†Ù‡ Ø§Ø«Ø± ØªØ¹Ø±Ø¶ Ø§Ù„Ø§Ø´Ø®Ø§Øµ ÙŠÙˆÙ… Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¹Ù…Ù„ÙŠÙ‡ Ø³Ù„Ø¨ Ù„Ù…Ø¨Ù„Øº Ù…Ø§Ù„ÙŠ Ù‚Ø¯Ø±Ù‡ Ø´Ø®ØµÙŠÙ† Ù…ØªÙ† Ø¯Ø±Ø§Ø¬Ù‡ Ù†Ø§Ø±ÙŠÙ‡ Ø§Ù„Ø§Ø¹ØªØ¯Ø§Ø¡ Ø¨ÙˆØ§Ø³Ø·Ù‡ Ø§Ù„Ù‡ Ø­Ø§Ø¯Ù‡ Ù…Ø³ØªÙˆÙ‰ Ø³Ø§Ù‚Ù‡ Ù†ØªØ¬ Ø¹Ù†Ù‡ ÙˆÙØ§ØªÙ‡ Ø§Ù„ØªØ­Ø±ÙŠØ§Øª Ø§Ù„Ù‡Ø§Ù„Ùƒ Ø¨Ø±ÙÙ‚Ù‡ Ø§ØµØ¯Ù‚Ø§Ø¦Ù‡ Ø²Ù…Ù† Ø§Ù„ÙˆØ§Ù‚Ø¹Ù‡ ØªØ¨ÙŠÙ† Ø§Ù†Ù‡ Ø§ØªØµÙ„ ÙŠÙˆÙ… Ø¨Ù†ÙØ±ÙŠÙ† Ø·Ø±ÙŠÙ‚ ÙˆØ³ÙŠØ· ÙˆØ§Ø¹Ù„Ù…Ù‡Ù…Ø§ Ø§Ù‚Ø§Ø±Ø¨Ù‡ Ø³ÙŠØ­Ø¶Ø± Ù…ÙƒØ§Ù† Ø§Ù„ÙˆØ§Ù‚Ø¹Ù‡ ÙˆØ¨Ø­ÙˆØ²ØªÙ‡ Ù…Ø¨Ù„Øº Ù…Ø§Ù„ÙŠ Ù‡Ø§Ù… Ø·Ù„Ø¨ Ù…Ù†Ù‡Ù…Ø§ Ø³Ù„Ø¨Ù‡ ÙˆØ§Ù‚ØªØ³Ø§Ù… Ø§Ù„Ù…Ø¨Ù„Øº Ù„Ø§Ø­Ù‚Ø§ ÙˆØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø³Ù†Ù‡ Ø§ÙƒØ¯ Ø¬Ø§Ø¡ Ø¨Ø§Ø·ÙˆØ§Ø± Ø§Ù„Ù‚Ø¶ÙŠÙ‡ ÙˆØ§Ø¹ØªØ±Ù Ø¨Ø·Ø¹Ù†Ù‡ Ù„Ù„Ù…ØªØ¶Ø±Ø± Ù…Ø³ØªÙˆÙ‰ Ø±Ø¬Ù„Ù‡ Ø§Ø¯Ù‰ Ù„Ø§Ø­Ù‚Ø§ Ù„ÙˆÙØ§ØªÙ‡ ØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨ Ù…Ø´ØªØ¨Ù‡ Ø§Ø®Ø±ÙŠÙ† ØªØªØ±Ø§ÙˆØ­ Ø§Ø¹Ù…Ø§Ø±Ù‡Ù… Ø³Ù†Ù‡ ÙˆØ­Ø¬Ø² Ù…Ø¨Ù„Øº Ù…Ø§Ù„ÙŠ Ù‚Ø¯Ø±Ù‡ Ø§Ù„Ø¯Ø±Ø§Ø¬Ù‡ Ø§Ù„Ù†Ø§Ø±ÙŠÙ‡ Ø§Ù„Ù…Ø³ØªØ¹Ù…Ù„Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠÙ‡']}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d518350b",
      "metadata": {
        "id": "d518350b"
      },
      "source": [
        "## Step 2: Load the Pretrained Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "277a333d",
      "metadata": {
        "id": "277a333d"
      },
      "source": [
        "Initialize a tokenizer from the gevin model checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a1931520",
      "metadata": {
        "id": "a1931520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a501771-a82d-4cab-f330-078043644b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/AraT5-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aff9f50",
      "metadata": {
        "id": "9aff9f50"
      },
      "source": [
        "## Step 3: Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a4a3ba9",
      "metadata": {
        "id": "1a4a3ba9"
      },
      "source": [
        "Define a preprocessing function that adds a prefix (\"summarize:\") to each input if needed and tokenizes the text for the model. The labels will be the tokenized summaries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.column_names"
      ],
      "metadata": {
        "id": "Sl72iRD_ndn9",
        "outputId": "af6f666c-e4d9-46bd-f5a5-fca84e14f472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Sl72iRD_ndn9",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Unnamed: 0', 'summarizer', 'text']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "a4d5f586",
      "metadata": {
        "id": "a4d5f586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "53516518e1ed4feeb358569f06c6aa74",
            "fa8bab0cb092431ba961be04b6509bc3",
            "2592fbe28b224cf3b39f50b3a4b3b8c0",
            "93eebedd90fb406f8941ee7516d5da11",
            "a599249528894e859fd66eba5562246d",
            "64f8b3c966ae46fab364004700050f11",
            "99765d2f0bb54c148d78f82caf51ec94",
            "a1edfd2cd4474c709fba955fc932d380",
            "e2e65592232a4d589a6e4107aba4b80c",
            "ad0d755b8f664e8c9c1d7ab1944609cb",
            "21c717d1da664fdd927abb12935e070d",
            "25ea3691771c45ddb15e0587c73401a1",
            "6ce3ce2c3ced416e99f2f4593a6f8af0",
            "62e1d0aabb454245a82ef887ce0cb2d9",
            "ed6edcf1362e4e5a83c099888887fd72",
            "a3f07b8a71424fb889a245a5b64ab93e",
            "5f69363c6d744a589804720f303c0311",
            "80f5c249c457426284e676417a8988c4",
            "3826316b052f4d2db1f798b5337c7f9a",
            "eddafb1fbf81427aa6cb51ccf7dce687",
            "2fb8629749f74b4bb46326fd25bdc0a3",
            "b6b1b7f6bcd84dbabadf238fc8fb032d"
          ]
        },
        "outputId": "379a3831-8862-48b2-c9ed-deaec7874605"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6702 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53516518e1ed4feeb358569f06c6aa74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1676 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25ea3691771c45ddb15e0587c73401a1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "\n",
        "    inputs = [\"summarize: \" + doc for doc in examples[\"text\"]]\n",
        "\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"summarizer\"], max_length=150, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "test_dataset = test_dataset.map(preprocess_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e898b873",
      "metadata": {
        "id": "e898b873"
      },
      "source": [
        "## Step 4: Define the Data Collator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42cc74fc",
      "metadata": {
        "id": "42cc74fc"
      },
      "source": [
        "Use a data collator designed for sequence-to-sequence models, which dynamically pads inputs and labels."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "991d5ded",
      "metadata": {
        "id": "991d5ded"
      },
      "source": [
        "## Step 5: Load the Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b67c4a",
      "metadata": {
        "id": "a4b67c4a"
      },
      "source": [
        "Load the model for sequence-to-sequence tasks (summarization)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(\"UBC-NLP/AraT5-base\")\n",
        "\n",
        "# ÙˆØ¸ÙŠÙØ© Ù„ØªØ­ÙˆÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø¥Ù„Ù‰ contiguous\n",
        "def make_contiguous(model):\n",
        "    for param in model.parameters():\n",
        "        if not param.is_contiguous():\n",
        "            param.data = param.data.contiguous()\n",
        "\n",
        "# Ø¬Ø¹Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¬Ø§ÙˆØ±Ù‹Ø§ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n",
        "make_contiguous(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "7ZzZeq1Ksgxq"
      },
      "id": "7ZzZeq1Ksgxq",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø£Ø¯Ø§Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n"
      ],
      "metadata": {
        "id": "zVXe9bgUs2wz",
        "outputId": "7c63bbf0-04e0-426c-9056-16e1dd74aa92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zVXe9bgUs2wz",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø£Ø¯Ø§Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = T5ForConditionalGeneration.from_pretrained(\"UBC-NLP/AraT5-base\")\n",
        "\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n",
        "#print(\"ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø§Ù‡Ø²...\")\n",
        "#model = T5ForConditionalGeneration.from_pretrained(\"UBC-NLP/AraT5-base\")\n",
        "\n",
        "# Ø¬Ø¹Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ¬Ø§ÙˆØ±Ù‹Ø§ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n",
        "#make_contiguous(model)\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n"
      ],
      "metadata": {
        "id": "_iAhgHOvn4de"
      },
      "id": "_iAhgHOvn4de",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f6276996",
      "metadata": {
        "id": "f6276996"
      },
      "source": [
        "## Step 6: Define Training Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fef9692",
      "metadata": {
        "id": "0fef9692"
      },
      "source": [
        "Set up the training configuration with parameters like learning rate, batch size, and number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "2a9710ac",
      "metadata": {
        "id": "2a9710ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d41018b-26bd-4404-8157-b11576204989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d109886",
      "metadata": {
        "id": "0d109886"
      },
      "source": [
        "## Step 7: Initialize the Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26da5a2",
      "metadata": {
        "id": "b26da5a2"
      },
      "source": [
        "Use the `Seq2SeqTrainer` class to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "287b64d0",
      "metadata": {
        "id": "287b64d0"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dea0d5d0",
      "metadata": {
        "id": "dea0d5d0"
      },
      "source": [
        "## Step 8: Fine-tune the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b78223",
      "metadata": {
        "id": "c1b78223"
      },
      "source": [
        "Train the model using the specified arguments and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "7183e3da",
      "metadata": {
        "id": "7183e3da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "c0215694-51bd-499d-d2d8-f6bc4a10dbc5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1676' max='1676' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1676/1676 13:40, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>7.715400</td>\n",
              "      <td>7.122348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1676, training_loss=8.885829006003878, metrics={'train_runtime': 820.8838, 'train_samples_per_second': 8.164, 'train_steps_per_second': 2.042, 'total_flos': 1576515858923520.0, 'train_loss': 8.885829006003878, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc4ae5b",
      "metadata": {
        "id": "dfc4ae5b"
      },
      "source": [
        "## Step 9: Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24f30dd0",
      "metadata": {
        "id": "24f30dd0"
      },
      "source": [
        "Once the model is trained, perform inference on a sample text to generate a summary. Use the tokenizer to process the text, and then feed it into the model to get the generated summary."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "TSAkJs_syhGq",
        "outputId": "e6b2fbb8-6670-447d-c2e8-b1575d612e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TSAkJs_syhGq",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(110080, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(110080, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(110080, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=110080, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text =\"ÙƒØ´Ù Ø®Ø¨ÙŠØ± Ù…ØµØ±ÙŠ Ø¹Ù† Ø¨Ø¹Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙŠ ØªØ³Ø±Ø¨Øª Ù…Ù† Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù‚ÙŠÙ‚Ø§Øª Ø£Ø­Ø¯Ø§Ø« 7 Ø£ÙƒØªÙˆØ¨Ø± Ø§Ù„Ù…Ø§Ø¶ÙŠ\""
      ],
      "metadata": {
        "id": "vVDUZKrJwsZd"
      },
      "id": "vVDUZKrJwsZd",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_text = \"ØªØ§Ø¨Ø¹ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ù…ØµØ±ÙŠ Ø£Ù† Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠÙ† Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠÙŠÙ†ØŒ ØªÙˆØ§ØµÙ„Ø§ Ù‡Ø§ØªÙÙŠØ§ØŒ ÙˆØ§ØªÙÙ‚Ø§ Ø¹Ù„Ù‰ Ø£Ù† Ù…Ø§ ÙŠØ­Ø¯Ø« Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù…Ø¬Ø±Ø¯ ØªØ¯Ø±ÙŠØ¨Ø§Øª Ù„Ø­Ù…Ø§Ø³ØŒ ÙˆÙ„Ø°Ù„Ùƒ Ù„Ù… ÙŠØªØ®Ø°Ø§ Ø£ÙŠ Ø¥Ø¬Ø±Ø§Ø¡ØŒ ÙƒÙ…Ø§ Ù„Ù… ÙŠØ±ÙØ¹Ø§ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ£Ù‡Ø¨ Ù„Ù„Ù‚ÙˆØ§Øª Ù…Ø«Ù„Ù…Ø§ Ù‡Ùˆ Ù…Ø¹ØªØ§Ø¯ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø±ØŒ Ù…Ø¤ÙƒØ¯Ø§ Ø£Ù† Ø§Ù„Ø¬ÙŠØ´ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ ÙÙˆØ¬Ø¦ ÙÙŠ Ø§Ù„ØµØ¨Ø§Ø­ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ù„Ù‡Ø¬ÙˆÙ… ÙˆØ§ÙƒØªØ´Ù Ù…Ù‚ØªÙ„ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø¬Ù†ÙˆØ¯Ù‡ ÙˆÙƒØ§Ù† Ø±Ø¯ ÙØ¹Ù„Ù‡ Ø¨Ø·ÙŠØ¦Ø§Ù‹ØŒ Ø­ÙŠØ« Ø§Ù‚ØªØµØ± Ø¹Ù„Ù‰ ØªØ­Ø±ÙŠÙƒ Ø§Ù„Ù…Ø±ÙˆØ­ÙŠØ§Øª Ø§Ù„Ø£Ø¨Ø§ØªØ´ÙŠ Ø§Ù„ØªÙŠ Ù‚ØªÙ„Øª Ø¹Ø¯Ø¯Ø§Ù‹ ÙƒØ¨ÙŠØ±Ø§Ù‹ Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ† ÙÙŠ Ø­ÙÙ„ Ù…ÙˆØ³ÙŠÙ‚ÙŠ Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ Ø®Ù„Ø§Ù„ Ù‡Ø±ÙˆØ¨Ù‡Ù…\"  # Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ Ù†Ø±ÙŠØ¯ ØªÙ„Ø®ÙŠØµÙ‡\n",
        "inputs = tokenizer(\"summarize: \" + sample_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "summary_ids = model.generate(inputs[\"input_ids\"])"
      ],
      "metadata": {
        "id": "Tqaf4YCwxhIA"
      },
      "id": "Tqaf4YCwxhIA",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(summary_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "p52AwWgjn97Z",
        "outputId": "209b8313-0d28-46e5-c513-2a6b55a5b8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p52AwWgjn97Z",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ø£ÙƒØ¯ Ø£Ù† ØªØµØ±ÙŠØ­ ØªØµØ±ÙŠØ­ ØªØµØ±ÙŠØ­ ØªØµØ±ÙŠØ­ ÙÙŠ ØªØµØ±ÙŠØ­ ÙÙŠ ØªØµØ±ÙŠØ­ ÙÙŠ ØªØµØ±ÙŠØ­ ÙÙŠ ØªØµØ±ÙŠØ­ ÙÙŠ ØªØµØ±ÙŠØ­ ÙÙŠ ØªØµØ±ÙŠØ­ ÙÙŠ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RPUp2BNUzo1a"
      },
      "id": "RPUp2BNUzo1a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53516518e1ed4feeb358569f06c6aa74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa8bab0cb092431ba961be04b6509bc3",
              "IPY_MODEL_2592fbe28b224cf3b39f50b3a4b3b8c0",
              "IPY_MODEL_93eebedd90fb406f8941ee7516d5da11"
            ],
            "layout": "IPY_MODEL_a599249528894e859fd66eba5562246d"
          }
        },
        "fa8bab0cb092431ba961be04b6509bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f8b3c966ae46fab364004700050f11",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_99765d2f0bb54c148d78f82caf51ec94",
            "value": "Map:â€‡100%"
          }
        },
        "2592fbe28b224cf3b39f50b3a4b3b8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1edfd2cd4474c709fba955fc932d380",
            "max": 6702,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e65592232a4d589a6e4107aba4b80c",
            "value": 6702
          }
        },
        "93eebedd90fb406f8941ee7516d5da11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad0d755b8f664e8c9c1d7ab1944609cb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_21c717d1da664fdd927abb12935e070d",
            "value": "â€‡6702/6702â€‡[00:01&lt;00:00,â€‡3904.88â€‡examples/s]"
          }
        },
        "a599249528894e859fd66eba5562246d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f8b3c966ae46fab364004700050f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99765d2f0bb54c148d78f82caf51ec94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1edfd2cd4474c709fba955fc932d380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e65592232a4d589a6e4107aba4b80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad0d755b8f664e8c9c1d7ab1944609cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21c717d1da664fdd927abb12935e070d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25ea3691771c45ddb15e0587c73401a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce3ce2c3ced416e99f2f4593a6f8af0",
              "IPY_MODEL_62e1d0aabb454245a82ef887ce0cb2d9",
              "IPY_MODEL_ed6edcf1362e4e5a83c099888887fd72"
            ],
            "layout": "IPY_MODEL_a3f07b8a71424fb889a245a5b64ab93e"
          }
        },
        "6ce3ce2c3ced416e99f2f4593a6f8af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f69363c6d744a589804720f303c0311",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_80f5c249c457426284e676417a8988c4",
            "value": "Map:â€‡100%"
          }
        },
        "62e1d0aabb454245a82ef887ce0cb2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3826316b052f4d2db1f798b5337c7f9a",
            "max": 1676,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eddafb1fbf81427aa6cb51ccf7dce687",
            "value": 1676
          }
        },
        "ed6edcf1362e4e5a83c099888887fd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb8629749f74b4bb46326fd25bdc0a3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b6b1b7f6bcd84dbabadf238fc8fb032d",
            "value": "â€‡1676/1676â€‡[00:00&lt;00:00,â€‡4168.75â€‡examples/s]"
          }
        },
        "a3f07b8a71424fb889a245a5b64ab93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f69363c6d744a589804720f303c0311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f5c249c457426284e676417a8988c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3826316b052f4d2db1f798b5337c7f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eddafb1fbf81427aa6cb51ccf7dce687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fb8629749f74b4bb46326fd25bdc0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6b1b7f6bcd84dbabadf238fc8fb032d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}